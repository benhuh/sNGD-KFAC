{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n",
      "170500096it [00:04, 39774696.47it/s]                                            \n",
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "=> We keep following layers in KFAC. \n",
      "(0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(13): Linear(in_features=512, out_features=10, bias=True)\n",
      "\n",
      "Epoch: 0\n",
      "/home/huh/miniconda3/envs/bfs/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "[kfac][LR=0.01] Loss: 1.400 | Acc: 49.426% (24713/50000): 100%|█| 782/782 [03:54<00:00,  3.34it/s]\n",
      "[kfac][LR=0.01] Loss: 1.113 | Acc: 62.260% (6226/10000): 100%|█| 40/40 [00:01<00:00, 32.71it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "[kfac][LR=0.01] Loss: 0.936 | Acc: 67.944% (33972/50000): 100%|█| 782/782 [03:45<00:00,  3.46it/s]\n",
      "[kfac][LR=0.01] Loss: 1.352 | Acc: 59.480% (5948/10000): 100%|█| 40/40 [00:01<00:00, 32.90it/s]\n",
      "\n",
      "Epoch: 2\n",
      "[kfac][LR=0.01] Loss: 0.753 | Acc: 74.510% (37255/50000): 100%|█| 782/782 [03:49<00:00,  3.41it/s]\n",
      "[kfac][LR=0.01] Loss: 0.762 | Acc: 74.300% (7430/10000): 100%|█| 40/40 [00:01<00:00, 31.69it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "[kfac][LR=0.01] Loss: 0.662 | Acc: 77.448% (38724/50000): 100%|█| 782/782 [03:50<00:00,  3.39it/s]\n",
      "[kfac][LR=0.01] Loss: 0.648 | Acc: 77.650% (7765/10000): 100%|█| 40/40 [00:01<00:00, 32.46it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "[kfac][LR=0.01] Loss: 0.611 | Acc: 79.404% (39702/50000): 100%|█| 782/782 [03:44<00:00,  3.48it/s]\n",
      "[kfac][LR=0.01] Loss: 0.605 | Acc: 79.810% (7981/10000): 100%|█| 40/40 [00:01<00:00, 32.77it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "[kfac][LR=0.01] Loss: 0.569 | Acc: 80.836% (40418/50000): 100%|█| 782/782 [03:20<00:00,  3.90it/s]\n",
      "[kfac][LR=0.01] Loss: 0.717 | Acc: 76.110% (7611/10000): 100%|█| 40/40 [00:01<00:00, 32.49it/s]\n",
      "\n",
      "Epoch: 6\n",
      "[kfac][LR=0.01] Loss: 0.538 | Acc: 81.842% (40921/50000): 100%|█| 782/782 [03:42<00:00,  3.52it/s]\n",
      "[kfac][LR=0.01] Loss: 0.596 | Acc: 79.700% (7970/10000): 100%|█| 40/40 [00:01<00:00, 30.15it/s]\n",
      "\n",
      "Epoch: 7\n",
      "[kfac][LR=0.01] Loss: 0.526 | Acc: 82.428% (41214/50000): 100%|█| 782/782 [03:41<00:00,  3.53it/s]\n",
      "[kfac][LR=0.01] Loss: 0.525 | Acc: 82.330% (8233/10000): 100%|█| 40/40 [00:01<00:00, 31.95it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "[kfac][LR=0.01] Loss: 0.519 | Acc: 82.704% (41352/50000): 100%|█| 782/782 [03:41<00:00,  3.53it/s]\n",
      "[kfac][LR=0.01] Loss: 0.547 | Acc: 80.820% (8082/10000): 100%|█| 40/40 [00:01<00:00, 32.93it/s]\n",
      "\n",
      "Epoch: 9\n",
      "[kfac][LR=0.01] Loss: 0.505 | Acc: 83.146% (41573/50000): 100%|█| 782/782 [03:40<00:00,  3.54it/s]\n",
      "[kfac][LR=0.01] Loss: 0.594 | Acc: 80.290% (8029/10000): 100%|█| 40/40 [00:01<00:00, 32.66it/s]\n",
      "\n",
      "Epoch: 10\n",
      "[kfac][LR=0.01] Loss: 0.498 | Acc: 83.448% (41724/50000): 100%|█| 782/782 [03:42<00:00,  3.51it/s]\n",
      "[kfac][LR=0.01] Loss: 0.672 | Acc: 77.790% (7779/10000): 100%|█| 40/40 [00:01<00:00, 32.45it/s]\n",
      "\n",
      "Epoch: 11\n",
      "[kfac][LR=0.01] Loss: 0.487 | Acc: 83.726% (41863/50000): 100%|█| 782/782 [03:21<00:00,  3.89it/s]\n",
      "[kfac][LR=0.01] Loss: 0.619 | Acc: 79.070% (7907/10000): 100%|█| 40/40 [00:01<00:00, 32.58it/s]\n",
      "\n",
      "Epoch: 12\n",
      "[kfac][LR=0.01] Loss: 0.483 | Acc: 83.824% (41912/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.01] Loss: 0.501 | Acc: 83.090% (8309/10000): 100%|█| 40/40 [00:01<00:00, 31.98it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 13\n",
      "[kfac][LR=0.01] Loss: 0.473 | Acc: 84.192% (42096/50000): 100%|█| 782/782 [03:46<00:00,  3.45it/s]\n",
      "[kfac][LR=0.01] Loss: 0.611 | Acc: 79.580% (7958/10000): 100%|█| 40/40 [00:01<00:00, 32.17it/s]\n",
      "\n",
      "Epoch: 14\n",
      "[kfac][LR=0.01] Loss: 0.465 | Acc: 84.602% (42301/50000): 100%|█| 782/782 [03:45<00:00,  3.48it/s]\n",
      "[kfac][LR=0.01] Loss: 0.576 | Acc: 80.770% (8077/10000): 100%|█| 40/40 [00:01<00:00, 31.95it/s]\n",
      "\n",
      "Epoch: 15\n",
      "[kfac][LR=0.01] Loss: 0.467 | Acc: 84.632% (42316/50000): 100%|█| 782/782 [03:45<00:00,  3.47it/s]\n",
      "[kfac][LR=0.01] Loss: 0.575 | Acc: 81.160% (8116/10000): 100%|█| 40/40 [00:01<00:00, 29.85it/s]\n",
      "\n",
      "Epoch: 16\n",
      "[kfac][LR=0.01] Loss: 0.464 | Acc: 84.436% (42218/50000): 100%|█| 782/782 [03:16<00:00,  3.97it/s]\n",
      "[kfac][LR=0.01] Loss: 0.510 | Acc: 83.170% (8317/10000): 100%|█| 40/40 [00:01<00:00, 31.92it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      "[kfac][LR=0.01] Loss: 0.457 | Acc: 84.820% (42410/50000): 100%|█| 782/782 [03:37<00:00,  3.60it/s]\n",
      "[kfac][LR=0.01] Loss: 0.550 | Acc: 81.880% (8188/10000): 100%|█| 40/40 [00:01<00:00, 31.16it/s]\n",
      "\n",
      "Epoch: 18\n",
      "[kfac][LR=0.01] Loss: 0.452 | Acc: 85.028% (42514/50000): 100%|█| 782/782 [03:45<00:00,  3.47it/s]\n",
      "[kfac][LR=0.01] Loss: 0.535 | Acc: 81.940% (8194/10000): 100%|█| 40/40 [00:01<00:00, 30.52it/s]\n",
      "\n",
      "Epoch: 19\n",
      "[kfac][LR=0.01] Loss: 0.451 | Acc: 84.878% (42439/50000): 100%|█| 782/782 [03:40<00:00,  3.55it/s]\n",
      "[kfac][LR=0.01] Loss: 0.654 | Acc: 78.650% (7865/10000): 100%|█| 40/40 [00:01<00:00, 31.29it/s]\n",
      "\n",
      "Epoch: 20\n",
      "[kfac][LR=0.01] Loss: 0.445 | Acc: 85.192% (42596/50000): 100%|█| 782/782 [03:37<00:00,  3.60it/s]\n",
      "[kfac][LR=0.01] Loss: 0.598 | Acc: 79.600% (7960/10000): 100%|█| 40/40 [00:01<00:00, 29.96it/s]\n",
      "\n",
      "Epoch: 21\n",
      "[kfac][LR=0.01] Loss: 0.442 | Acc: 85.468% (42734/50000): 100%|█| 782/782 [03:39<00:00,  3.57it/s]\n",
      "[kfac][LR=0.01] Loss: 0.457 | Acc: 85.330% (8533/10000): 100%|█| 40/40 [00:01<00:00, 31.30it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 22\n",
      "[kfac][LR=0.01] Loss: 0.435 | Acc: 85.636% (42818/50000): 100%|█| 782/782 [03:17<00:00,  3.97it/s]\n",
      "[kfac][LR=0.01] Loss: 0.497 | Acc: 83.410% (8341/10000): 100%|█| 40/40 [00:01<00:00, 31.44it/s]\n",
      "\n",
      "Epoch: 23\n",
      "[kfac][LR=0.01] Loss: 0.440 | Acc: 85.290% (42645/50000): 100%|█| 782/782 [03:39<00:00,  3.57it/s]\n",
      "[kfac][LR=0.01] Loss: 0.549 | Acc: 82.400% (8240/10000): 100%|█| 40/40 [00:01<00:00, 29.83it/s]\n",
      "\n",
      "Epoch: 24\n",
      "[kfac][LR=0.01] Loss: 0.438 | Acc: 85.468% (42734/50000): 100%|█| 782/782 [03:39<00:00,  3.55it/s]\n",
      "[kfac][LR=0.01] Loss: 0.589 | Acc: 81.660% (8166/10000): 100%|█| 40/40 [00:01<00:00, 31.55it/s]\n",
      "\n",
      "Epoch: 25\n",
      "[kfac][LR=0.01] Loss: 0.435 | Acc: 85.642% (42821/50000): 100%|█| 782/782 [03:40<00:00,  3.55it/s]\n",
      "[kfac][LR=0.01] Loss: 0.493 | Acc: 83.620% (8362/10000): 100%|█| 40/40 [00:01<00:00, 31.32it/s]\n",
      "\n",
      "Epoch: 26\n",
      "[kfac][LR=0.01] Loss: 0.434 | Acc: 85.844% (42922/50000): 100%|█| 782/782 [03:41<00:00,  3.53it/s]\n",
      "[kfac][LR=0.01] Loss: 0.596 | Acc: 79.650% (7965/10000): 100%|█| 40/40 [00:01<00:00, 30.73it/s]\n",
      "\n",
      "Epoch: 27\n",
      "[kfac][LR=0.01] Loss: 0.430 | Acc: 85.742% (42871/50000): 100%|█| 782/782 [03:19<00:00,  3.91it/s]\n",
      "[kfac][LR=0.01] Loss: 0.474 | Acc: 84.610% (8461/10000): 100%|█| 40/40 [00:01<00:00, 28.74it/s]\n",
      "\n",
      "Epoch: 28\n",
      "[kfac][LR=0.01] Loss: 0.429 | Acc: 85.738% (42869/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.01] Loss: 0.472 | Acc: 84.360% (8436/10000): 100%|█| 40/40 [00:01<00:00, 28.43it/s]\n",
      "\n",
      "Epoch: 29\n",
      "[kfac][LR=0.01] Loss: 0.428 | Acc: 85.764% (42882/50000): 100%|█| 782/782 [03:40<00:00,  3.54it/s]\n",
      "[kfac][LR=0.01] Loss: 0.611 | Acc: 80.840% (8084/10000): 100%|█| 40/40 [00:01<00:00, 30.86it/s]\n",
      "\n",
      "Epoch: 30\n",
      "[kfac][LR=0.01] Loss: 0.428 | Acc: 86.050% (43025/50000): 100%|█| 782/782 [03:39<00:00,  3.57it/s]\n",
      "[kfac][LR=0.01] Loss: 0.562 | Acc: 81.290% (8129/10000): 100%|█| 40/40 [00:01<00:00, 31.32it/s]\n",
      "\n",
      "Epoch: 31\n",
      "[kfac][LR=0.01] Loss: 0.427 | Acc: 85.934% (42967/50000): 100%|█| 782/782 [03:42<00:00,  3.52it/s]\n",
      "[kfac][LR=0.01] Loss: 0.534 | Acc: 82.760% (8276/10000): 100%|█| 40/40 [00:01<00:00, 30.18it/s]\n",
      "\n",
      "Epoch: 32\n",
      "[kfac][LR=0.01] Loss: 0.422 | Acc: 86.010% (43005/50000): 100%|█| 782/782 [03:39<00:00,  3.56it/s]\n",
      "[kfac][LR=0.01] Loss: 0.621 | Acc: 79.700% (7970/10000): 100%|█| 40/40 [00:01<00:00, 30.31it/s]\n",
      "\n",
      "Epoch: 33\n",
      "[kfac][LR=0.01] Loss: 0.421 | Acc: 86.178% (43089/50000): 100%|█| 782/782 [03:15<00:00,  4.00it/s]\n",
      "[kfac][LR=0.01] Loss: 0.613 | Acc: 81.250% (8125/10000): 100%|█| 40/40 [00:01<00:00, 29.19it/s]\n",
      "\n",
      "Epoch: 34\n",
      "[kfac][LR=0.01] Loss: 0.418 | Acc: 86.164% (43082/50000): 100%|█| 782/782 [03:39<00:00,  3.57it/s]\n",
      "[kfac][LR=0.01] Loss: 0.509 | Acc: 83.250% (8325/10000): 100%|█| 40/40 [00:01<00:00, 30.57it/s]\n",
      "\n",
      "Epoch: 35\n",
      "[kfac][LR=0.01] Loss: 0.424 | Acc: 86.036% (43018/50000): 100%|█| 782/782 [03:40<00:00,  3.55it/s]\n",
      "[kfac][LR=0.01] Loss: 0.487 | Acc: 83.580% (8358/10000): 100%|█| 40/40 [00:01<00:00, 31.21it/s]\n",
      "\n",
      "Epoch: 36\n",
      "[kfac][LR=0.01] Loss: 0.416 | Acc: 86.116% (43058/50000): 100%|█| 782/782 [03:38<00:00,  3.58it/s]\n",
      "[kfac][LR=0.01] Loss: 0.674 | Acc: 78.510% (7851/10000): 100%|█| 40/40 [00:01<00:00, 31.08it/s]\n",
      "\n",
      "Epoch: 37\n",
      "[kfac][LR=0.01] Loss: 0.417 | Acc: 86.140% (43070/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.01] Loss: 0.487 | Acc: 84.060% (8406/10000): 100%|█| 40/40 [00:01<00:00, 30.34it/s]\n",
      "\n",
      "Epoch: 38\n",
      "[kfac][LR=0.01] Loss: 0.417 | Acc: 86.276% (43138/50000): 100%|█| 782/782 [03:17<00:00,  3.95it/s]\n",
      "[kfac][LR=0.01] Loss: 0.605 | Acc: 81.150% (8115/10000): 100%|█| 40/40 [00:01<00:00, 28.07it/s]\n",
      "\n",
      "Epoch: 39\n",
      "[kfac][LR=0.001] Loss: 0.233 | Acc: 92.412% (46206/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.001] Loss: 0.265 | Acc: 91.300% (9130/10000): 100%|█| 40/40 [00:01<00:00, 30.23it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 40\n",
      "[kfac][LR=0.001] Loss: 0.177 | Acc: 94.188% (47094/50000): 100%|█| 782/782 [03:38<00:00,  3.57it/s]  \n",
      "[kfac][LR=0.001] Loss: 0.248 | Acc: 91.850% (9185/10000): 100%|█| 40/40 [00:01<00:00, 30.50it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 41\n",
      "[kfac][LR=0.001] Loss: 0.154 | Acc: 95.018% (47509/50000): 100%|█| 782/782 [03:40<00:00,  3.54it/s]\n",
      "[kfac][LR=0.001] Loss: 0.246 | Acc: 91.940% (9194/10000): 100%|█| 40/40 [00:01<00:00, 29.89it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 42\n",
      "[kfac][LR=0.001] Loss: 0.128 | Acc: 95.820% (47910/50000): 100%|█| 782/782 [03:37<00:00,  3.59it/s]\n",
      "[kfac][LR=0.001] Loss: 0.246 | Acc: 92.380% (9238/10000): 100%|█| 40/40 [00:01<00:00, 30.30it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 44\n",
      "[kfac][LR=0.001] Loss: 0.118 | Acc: 96.082% (48041/50000): 100%|█| 782/782 [03:16<00:00,  3.98it/s]\n",
      "[kfac][LR=0.001] Loss: 0.252 | Acc: 92.250% (9225/10000): 100%|█| 40/40 [00:01<00:00, 28.34it/s]\n",
      "\n",
      "Epoch: 45\n",
      "[kfac][LR=0.001] Loss: 0.110 | Acc: 96.356% (48178/50000): 100%|█| 782/782 [03:40<00:00,  3.54it/s]\n",
      "[kfac][LR=0.001] Loss: 0.243 | Acc: 92.670% (9267/10000): 100%|█| 40/40 [00:01<00:00, 29.25it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 46\n",
      "[kfac][LR=0.001] Loss: 0.100 | Acc: 96.694% (48347/50000): 100%|█| 782/782 [03:38<00:00,  3.57it/s]\n",
      "[kfac][LR=0.001] Loss: 0.254 | Acc: 92.420% (9242/10000): 100%|█| 40/40 [00:01<00:00, 29.80it/s]\n",
      "\n",
      "Epoch: 47\n",
      "[kfac][LR=0.001] Loss: 0.089 | Acc: 97.047% (28136/28992):  58%|▌| 453/782 [02:14<09:43,  1.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kfac][LR=0.001] Loss: 0.081 | Acc: 97.318% (48659/50000): 100%|█| 782/782 [03:50<00:00,  3.40it/s]\n",
      "[kfac][LR=0.001] Loss: 0.291 | Acc: 92.070% (9207/10000): 100%|█| 40/40 [00:01<00:00, 27.69it/s]\n",
      "\n",
      "Epoch: 54\n",
      "[kfac][LR=0.001] Loss: 0.078 | Acc: 97.472% (48736/50000): 100%|█| 782/782 [03:48<00:00,  3.42it/s]\n",
      "[kfac][LR=0.001] Loss: 0.281 | Acc: 92.050% (9205/10000): 100%|█| 40/40 [00:01<00:00, 29.79it/s]\n",
      "\n",
      "Epoch: 55\n",
      "[kfac][LR=0.001] Loss: 0.077 | Acc: 97.492% (48746/50000): 100%|█| 782/782 [03:26<00:00,  3.78it/s]\n",
      "[kfac][LR=0.001] Loss: 0.285 | Acc: 91.960% (9196/10000): 100%|█| 40/40 [00:01<00:00, 29.61it/s]\n",
      "\n",
      "Epoch: 56\n",
      "[kfac][LR=0.001] Loss: 0.076 | Acc: 97.550% (48775/50000): 100%|█| 782/782 [03:49<00:00,  3.41it/s]\n",
      "[kfac][LR=0.001] Loss: 0.276 | Acc: 92.180% (9218/10000): 100%|█| 40/40 [00:01<00:00, 29.87it/s]\n",
      "\n",
      "Epoch: 57\n",
      "[kfac][LR=0.001] Loss: 0.074 | Acc: 97.558% (48779/50000): 100%|█| 782/782 [03:49<00:00,  3.41it/s]\n",
      "[kfac][LR=0.001] Loss: 0.296 | Acc: 91.360% (9136/10000): 100%|█| 40/40 [00:01<00:00, 27.19it/s]\n",
      "\n",
      "Epoch: 58\n",
      "[kfac][LR=0.001] Loss: 0.066 | Acc: 97.900% (9649/9856):  20%|▏| 154/782 [00:53<13:02,  1.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kfac][LR=0.001] Loss: 0.075 | Acc: 97.496% (48748/50000): 100%|█| 782/782 [03:53<00:00,  3.35it/s]\n",
      "[kfac][LR=0.001] Loss: 0.279 | Acc: 92.170% (9217/10000): 100%|█| 40/40 [00:01<00:00, 27.35it/s]\n",
      "\n",
      "Epoch: 65\n",
      "[kfac][LR=0.001] Loss: 0.075 | Acc: 97.508% (48754/50000): 100%|█| 782/782 [03:47<00:00,  3.43it/s]\n",
      "[kfac][LR=0.001] Loss: 0.290 | Acc: 91.850% (9185/10000): 100%|█| 40/40 [00:01<00:00, 27.12it/s]\n",
      "\n",
      "Epoch: 66\n",
      "[kfac][LR=0.001] Loss: 0.085 | Acc: 97.188% (48594/50000): 100%|█| 782/782 [03:17<00:00,  3.96it/s]\n",
      "[kfac][LR=0.001] Loss: 0.298 | Acc: 91.750% (9175/10000): 100%|█| 40/40 [00:01<00:00, 29.46it/s]\n",
      "\n",
      "Epoch: 67\n",
      "[kfac][LR=0.001] Loss: 0.080 | Acc: 97.378% (48689/50000): 100%|█| 782/782 [03:48<00:00,  3.43it/s]\n",
      "[kfac][LR=0.001] Loss: 0.304 | Acc: 91.530% (9153/10000): 100%|█| 40/40 [00:01<00:00, 26.77it/s]\n",
      "\n",
      "Epoch: 68\n",
      "[kfac][LR=0.001] Loss: 0.082 | Acc: 97.246% (48623/50000): 100%|█| 782/782 [03:56<00:00,  3.31it/s]\n",
      "[kfac][LR=0.001] Loss: 0.311 | Acc: 91.480% (9148/10000): 100%|█| 40/40 [00:01<00:00, 28.87it/s]\n",
      "\n",
      "Epoch: 69\n",
      "[kfac][LR=0.001] Loss: 0.080 | Acc: 97.452% (48726/50000): 100%|█| 782/782 [03:53<00:00,  3.34it/s]\n",
      "[kfac][LR=0.001] Loss: 0.299 | Acc: 91.480% (9148/10000): 100%|█| 40/40 [00:01<00:00, 28.94it/s]\n",
      "\n",
      "Epoch: 70\n",
      "[kfac][LR=0.001] Loss: 0.076 | Acc: 97.628% (48814/50000): 100%|█| 782/782 [03:48<00:00,  3.43it/s]\n",
      "[kfac][LR=0.001] Loss: 0.314 | Acc: 91.410% (9141/10000): 100%|█| 40/40 [00:01<00:00, 27.33it/s]\n",
      "\n",
      "Epoch: 71\n",
      "[kfac][LR=0.001] Loss: 0.079 | Acc: 97.388% (48694/50000): 100%|█| 782/782 [03:47<00:00,  3.43it/s]\n",
      "[kfac][LR=0.001] Loss: 0.294 | Acc: 91.810% (9181/10000): 100%|█| 40/40 [00:01<00:00, 27.60it/s]\n",
      "\n",
      "Epoch: 72\n",
      "[kfac][LR=0.001] Loss: 0.084 | Acc: 97.312% (48656/50000): 100%|█| 782/782 [03:23<00:00,  3.84it/s]\n",
      "[kfac][LR=0.001] Loss: 0.314 | Acc: 91.670% (9167/10000): 100%|█| 40/40 [00:01<00:00, 26.26it/s]\n",
      "\n",
      "Epoch: 73\n",
      "[kfac][LR=0.001] Loss: 0.085 | Acc: 97.144% (48572/50000): 100%|█| 782/782 [03:48<00:00,  3.42it/s]\n",
      "[kfac][LR=0.001] Loss: 0.301 | Acc: 91.580% (9158/10000): 100%|█| 40/40 [00:01<00:00, 26.90it/s]\n",
      "\n",
      "Epoch: 74\n",
      "[kfac][LR=0.001] Loss: 0.080 | Acc: 97.408% (48704/50000): 100%|█| 782/782 [03:46<00:00,  3.45it/s]\n",
      "[kfac][LR=0.001] Loss: 0.304 | Acc: 91.230% (9123/10000): 100%|█| 40/40 [00:01<00:00, 26.34it/s]\n",
      "\n",
      "Epoch: 75\n",
      "[kfac][LR=0.001] Loss: 0.083 | Acc: 97.268% (48634/50000): 100%|█| 782/782 [03:46<00:00,  3.45it/s]\n",
      "[kfac][LR=0.001] Loss: 0.289 | Acc: 91.980% (9198/10000): 100%|█| 40/40 [00:01<00:00, 28.40it/s]\n",
      "\n",
      "Epoch: 76\n",
      "[kfac][LR=0.001] Loss: 0.083 | Acc: 97.278% (48639/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.001] Loss: 0.285 | Acc: 91.980% (9198/10000): 100%|█| 40/40 [00:01<00:00, 29.03it/s]\n",
      "\n",
      "Epoch: 77\n",
      "[kfac][LR=0.001] Loss: 0.080 | Acc: 97.356% (48678/50000): 100%|█| 782/782 [03:22<00:00,  3.86it/s]\n",
      "[kfac][LR=0.001] Loss: 0.312 | Acc: 91.230% (9123/10000): 100%|█| 40/40 [00:01<00:00, 28.58it/s]\n",
      "\n",
      "Epoch: 78\n",
      "[kfac][LR=0.001] Loss: 0.081 | Acc: 97.334% (48667/50000): 100%|█| 782/782 [03:42<00:00,  3.51it/s]\n",
      "[kfac][LR=0.001] Loss: 0.301 | Acc: 91.680% (9168/10000): 100%|█| 40/40 [00:01<00:00, 28.77it/s]\n",
      "\n",
      "Epoch: 79\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.041 | Acc: 98.742% (49371/50000): 100%|█| 782/782 [03:45<00:00,  3.46it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.249 | Acc: 93.160% (9316/10000): 100%|█| 40/40 [00:01<00:00, 28.84it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 80\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.025 | Acc: 99.256% (49628/50000): 100%|█| 782/782 [03:43<00:00,  3.50it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.247 | Acc: 93.480% (9348/10000): 100%|█| 40/40 [00:01<00:00, 29.16it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 81\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.021 | Acc: 99.422% (49711/50000): 100%|█| 782/782 [03:44<00:00,  3.48it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.241 | Acc: 93.640% (9364/10000): 100%|█| 40/40 [00:01<00:00, 28.30it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 82\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.019 | Acc: 99.504% (49752/50000): 100%|█| 782/782 [03:43<00:00,  3.51it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.247 | Acc: 93.610% (9361/10000): 100%|█| 40/40 [00:01<00:00, 27.86it/s]\n",
      "\n",
      "Epoch: 83\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.015 | Acc: 99.628% (49814/50000): 100%|█| 782/782 [03:16<00:00,  3.98it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.250 | Acc: 93.620% (9362/10000): 100%|█| 40/40 [00:01<00:00, 26.18it/s]\n",
      "\n",
      "Epoch: 84\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.015 | Acc: 99.610% (49805/50000): 100%|█| 782/782 [03:41<00:00,  3.53it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.252 | Acc: 93.720% (9372/10000): 100%|█| 40/40 [00:01<00:00, 28.31it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 85\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.013 | Acc: 99.660% (49830/50000): 100%|█| 782/782 [03:40<00:00,  3.54it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.256 | Acc: 93.880% (9388/10000): 100%|█| 40/40 [00:01<00:00, 27.45it/s]\n",
      "Saving..\n",
      "\n",
      "Epoch: 86\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.012 | Acc: 99.703% (47730/47872):  96%|▉| 747/782 [03:16<00:01, 20.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kfac][LR=0.00010000000000000002] Loss: 0.009 | Acc: 99.798% (49899/50000): 100%|█| 782/782 [03:42<00:00,  3.52it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.263 | Acc: 93.840% (9384/10000): 100%|█| 40/40 [00:01<00:00, 25.46it/s]\n",
      "\n",
      "Epoch: 93\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.009 | Acc: 99.822% (49911/50000): 100%|█| 782/782 [03:42<00:00,  3.51it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.263 | Acc: 93.850% (9385/10000): 100%|█| 40/40 [00:01<00:00, 25.44it/s]\n",
      "\n",
      "Epoch: 94\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.008 | Acc: 99.844% (49922/50000): 100%|█| 782/782 [03:21<00:00,  3.88it/s]\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.261 | Acc: 93.950% (9395/10000): 100%|█| 40/40 [00:01<00:00, 25.07it/s]\n",
      "\n",
      "Epoch: 95\n",
      "[kfac][LR=0.00010000000000000002] Loss: 0.008 | Acc: 99.825% (32583/32640):  65%|▋| 509/782 [02:23<00:13, 20.45it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python main.py --dataset cifar10 --optimizer kfac --network vgg16_bn  --epoch 100 --milestone 40,80 --learning_rate 0.01 --damping 0.03 --weight_decay 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --dataset cifar10 --optimizer kfac --network vgg11_0  --epoch 100 --milestone 40,80 --learning_rate 0.01 --stat_decay 0 --TCov 1 --damping 1e-9 --weight_decay 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "=> We keep following layers in KFAC. \n",
      "(0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(8): Linear(in_features=512, out_features=10, bias=True)\n",
      "\n",
      "Epoch: 0\n",
      "/home/huh/miniconda3/envs/bfs/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "[kfac][LR=0.01] Loss: 0.000 | Acc: 0.000% (0/0):   0%|  | 0/782 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!python main.py --dataset cifar10 --optimizer kfac --network vgg11  --epoch 100 --milestone 40,80 --learning_rate 0.01 --stat_decay 0.95 --TCov 10 --damping 1e-9 --weight_decay 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bfs] *",
   "language": "python",
   "name": "conda-env-bfs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
